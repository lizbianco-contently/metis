{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import re\n",
    "import pandas as pd\n",
    "import dateutil.parser\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import csv\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape_congress(session):\n",
    "    url = 'https://www.congress.gov/congressional-record/'+session+'113th-congress/browse-by-date'\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    all_links = []\n",
    "    for link in soup.find_all('a'):\n",
    "        all_links.append(link.get('href'))\n",
    "    senate_links = []\n",
    "    house_links = []\n",
    "    for link in all_links:\n",
    "        if \"senate-section\" in link:\n",
    "            senate_links.append(link)\n",
    "        if \"house-section\" in link:\n",
    "            house_links.append(link)\n",
    "    print (str(len(senate_links))+ ' in senate')\n",
    "    print (str(len(house_links))+ ' in the house')\n",
    "    for i in senate_links:\n",
    "        url = 'http://www.congress.gov'+i\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        links_by_day = []\n",
    "        for j in soup.find_all('a'):\n",
    "            links_by_day.append(j.get('href'))\n",
    "        article_texts = []\n",
    "        for k  in temp_article_links:\n",
    "            url='http://www.congress.gov'+k\n",
    "            response = requests.get(url)\n",
    "            page = response.text\n",
    "            soup = BeautifulSoup(page, \"html.parser\")\n",
    "            originaltext = soup.find(class_='styles').text\n",
    "            day = k.split('/')[4]\n",
    "            month = k.split('/')[3]\n",
    "            year = k.split('/')[2]\n",
    "            tempdict = {\"url\": url, \"originaltext\": originaltext, \"day\":day, \"month\":month, \"year\":year}\n",
    "            article_texts.append(tempdict)\n",
    "        filename = 'Data/'+session+'congress/'+session+'senate/'+year+'_'+month+'_'+day\n",
    "        with open(filename, 'w') as outfile:\n",
    "            json.dump(article_texts, outfile)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 in senate\n",
      "0 in the house\n"
     ]
    }
   ],
   "source": [
    "scrape_congress('112')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_congress(session):\n",
    "    url = 'https://www.congress.gov/congressional-record/'+session+'113th-congress/browse-by-date'\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
